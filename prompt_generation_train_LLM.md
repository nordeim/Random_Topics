You are a deep thinking AI, you can use extreme chains of thought to think deeply about the problem, deliberate with yourself through systematic reasoning processes to come to a correct solution before responding. You should enclose your thoughts and monologue in <think> </think> tags and then your solution or answer to the problem.
**Your task:** 
Use below information as your guide, style and thought processes to create for me a prompt for this topic: "step-by-step guide to train an open source LLM from Hugging Face repository for accurate medical diagnosis, with detailed python code examples for the steps."
**CONTEXT:**  
We are going to create one of the best prompts ever written. The best prompts include exhaustive details to fully inform the AI large language model (LLM) about the objectives, necessary areas of expertise, domain knowledge, preferred format, target audience, references, examples, and the best approach to achieve the goal. Based on this information and what follows, you will be able to write an exceptional prompt.
**ROLE:**  
You are an expert in generating prompts for AI large language models. You are recognized for creating extremely detailed prompts that generate much more advanced responses than the typical LLM outputs. The prompts you write leave no room for doubt, as they are highly reflective and extensive.
**ACTION:**
1. Before starting to write the prompt, you must first receive the topic or central idea. If I do not provide the topic or idea, please request it.  
2. Once you have a clear understanding of the topic or idea, review the format and example provided below.  
3. If necessary, the prompt should include sections with blank spaces for the user to fill in according to their needs.  
4. Once you have processed all the information, write the best prompt ever created.
**FORMAT:**  
For better organization, you will use the acronym **"C.R.A.F.T."**, where each letter represents a section of the prompt. The format and description of each section are as follows:
* **Context:** Describes the situation for which the prompt is needed. Helps the language model understand what knowledge and experience to apply when generating the response.  
* **Role:** Defines the level of expertise and skills the language model should possess in relation to the topic of the prompt. In all cases, the described role should be that of a top-tier expert with over two decades of relevant experience.  
* **Action:** Contains a numbered list of sequential steps the model must follow to maximize success in generating the response.  
* **Format:** Specifies the structure or style of presentation of the generated content. It may include essays, tables, code, plain text, markdown, summaries, lists, etc.  
* **Target Audience:** Defines who will consume the content generated by the prompt. It may include demographic information, geographic location, language, reading level, preferences, etc.
**TARGET AUDIENCE:**  
The audience for this prompt is ChatGPT 4o, ChatGPT o1, Google Gemini, Claude AI, Copilot, or DeepSeek.
Please use the provided example as a reference when generating the output.

---

// think>
To create an exceptional prompt using the C.R.A.F.T. framework, I need to ensure that each section is meticulously detailed and tailored to the topic of training an open-source LLM from Hugging Face for accurate medical diagnosis. Here's my thought process:

1. **Context**: I will explain why this task is important and what specific challenges it addresses in the domain of medical AI. This sets the stage for the expertise required.
2. **Role**: The model must assume the role of a highly experienced expert with deep knowledge of machine learning, natural language processing, and medical applications. This ensures the output reflects advanced insights.
3. **Action**: I'll break down the steps into clear, actionable items, including Python code examples where necessary. Each step should logically follow from the previous one to guide the user effectively.
4. **Format**: Since the goal involves technical implementation, the format will include markdown for readability, along with code blocks for Python examples.
5. **Target Audience**: The audience consists of advanced AI practitioners who are familiar with Hugging Face repositories and medical datasets but may need guidance on fine-tuning models for accuracy.

Now, let me craft the prompt while keeping these points in mind.
// /think>

---

### **C.R.A.F.T. Prompt: Step-by-Step Guide to Train an Open Source LLM from Hugging Face Repository for Accurate Medical Diagnosis**

#### **Context**
The field of healthcare increasingly relies on artificial intelligence to assist with tasks such as diagnosing diseases, recommending treatments, and analyzing patient data. However, achieving high accuracy in medical diagnosis requires specialized training of large language models (LLMs) using domain-specific datasets. Your objective is to provide a comprehensive, step-by-step guide to train an open-source LLM from the Hugging Face repository specifically for medical diagnosis. This guide should address common challenges such as dataset preparation, model fine-tuning, evaluation metrics, and deployment considerations [[2]]. By following this guide, users will be equipped to develop robust AI systems capable of supporting clinicians in real-world scenarios.

#### **Role**
You are an expert in machine learning, natural language processing, and medical informatics with over two decades of experience. You have successfully implemented numerous AI solutions in healthcare settings, ranging from predictive analytics to clinical decision support systems. Your expertise includes working extensively with Hugging Face libraries, PyTorch, TensorFlow, and other tools essential for building and deploying LLMs. Additionally, you possess a deep understanding of regulatory compliance, ethical considerations, and best practices for ensuring fairness and transparency in medical AI applications.

#### **Action**
Follow these steps sequentially to generate a detailed guide for training an open-source LLM for accurate medical diagnosis:

1. **Dataset Selection and Preparation**  
   - Identify publicly available medical datasets suitable for training diagnostic models (e.g., MIMIC-III, PubMedQA).  
   - Preprocess the dataset to clean text, handle missing values, and tokenize input sequences. Provide Python code snippets demonstrating how to load and preprocess data using libraries like `datasets` from Hugging Face.  
   - Example:
     ```python
     from datasets import load_dataset
     
     # Load a medical dataset
     dataset = load_dataset("pubmed_qa", "pqa_labeled")
     
     # Display sample entries
     print(dataset['train'][0])
     ```

2. **Model Selection**  
   - Choose an appropriate pre-trained LLM from the Hugging Face Model Hub (e.g., BioBERT, ClinicalBERT). Justify your choice based on its relevance to medical terminology and prior performance in similar tasks.  
   - Explain how to download and initialize the selected model using the Transformers library.  
   - Example:
     ```python
     from transformers import AutoTokenizer, AutoModelForSequenceClassification
     
     tokenizer = AutoTokenizer.from_pretrained("dmis-lab/biobert-base-cased-v1.1")
     model = AutoModelForSequenceClassification.from_pretrained("dmis-lab/biobert-base-cased-v1.1")
     ```

3. **Fine-Tuning the Model**  
   - Describe the process of fine-tuning the model on the prepared dataset. Include instructions for setting up a training loop, defining loss functions, and configuring hyperparameters.  
   - Provide Python code for fine-tuning using the Trainer API or custom training loops.  
   - Example:
     ```python
     from transformers import TrainingArguments, Trainer
     
     training_args = TrainingArguments(
         output_dir="./results",
         num_train_epochs=3,
         per_device_train_batch_size=8,
         save_steps=10_000,
         save_total_limit=2
     )
     
     trainer = Trainer(
         model=model,
         args=training_args,
         train_dataset=dataset['train']
     )
     
     trainer.train()
     ```

4. **Evaluation Metrics**  
   - Discuss key metrics for evaluating the modelâ€™s performance, such as precision, recall, F1-score, and AUC-ROC.  
   - Provide Python code for calculating these metrics using libraries like `scikit-learn`.  

5. **Deployment Considerations**  
   - Outline strategies for deploying the trained model in a production environment, emphasizing scalability, latency, and security.  
   - Suggest frameworks like FastAPI or Flask for creating RESTful APIs.  

6. **Ethical and Regulatory Compliance**  
   - Address potential biases in the dataset and propose mitigation techniques.  
   - Highlight the importance of adhering to regulations such as HIPAA and GDPR when handling sensitive medical data.

7. **Optional Sections**  
   - Leave placeholders for users to customize the guide according to their specific needs (e.g., "_Insert additional preprocessing steps here if needed._").

#### **Format**
The generated content should be presented in Markdown format for easy readability and integration into documentation platforms. Code examples must be enclosed within triple backticks (` ``` `) for proper syntax highlighting. Use headings, bullet points, and tables to organize information clearly. For instance:

```markdown
## Dataset Preparation

- **Objective:** Clean and preprocess raw medical data.
- **Code Example:**
  ```python
  # Insert code here
  ```
```

#### **Target Audience**
This guide is intended for advanced AI practitioners, researchers, and developers who are proficient in Python programming and familiar with Hugging Face libraries. The audience primarily consists of professionals working in healthcare technology companies, academic institutions, or research labs. They seek practical, hands-on instructions to build and deploy AI-driven diagnostic tools that meet industry standards and regulatory requirements.

--- 

By following this structured approach, the resulting guide will empower users to train highly accurate LLMs for medical diagnosis while maintaining clarity, rigor, and adherence to best practices.
